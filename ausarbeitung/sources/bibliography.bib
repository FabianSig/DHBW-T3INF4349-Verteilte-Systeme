@inproceedings{weigand-etal-2022-conspiracy,
    title = "Conspiracy Narratives in the Protest Movement Against {COVID}-19 Restrictions in {G}ermany. A Long-term Content Analysis of Telegram Chat Groups.",
    author = "Weigand, Manuel  and
      Weber, Maximilian  and
      Gruber, Johannes",
    editor = "Bamman, David  and
      Hovy, Dirk  and
      Jurgens, David  and
      Keith, Katherine  and
      O'Connor, Brendan  and
      Volkova, Svitlana",
    booktitle = "Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science (NLP+CSS)",
    month = nov,
    year = "2022",
    address = "Abu Dhabi, UAE",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.nlpcss-1.8",
    doi = "10.18653/v1/2022.nlpcss-1.8",
    pages = "52--58",
    abstract = "From the start of the COVID-19 pandemic in Germany, different groups have been protesting measures implemented by different government bodies in Germany to control the pandemic. It was widely claimed that many of the offline and online protests were driven by conspiracy narratives disseminated through groups and channels on the messenger app Telegram. We investigate this claim by measuring the frequency of conspiracy narratives in messages from open Telegram chat groups of the Querdenken movement, set up to organize protests against COVID-19 restrictions in Germany. We furthermore explore the content of these messages using topic modelling. To this end, we collected 822k text messages sent between April 2020 and May 2022 in 34 chat groups. By fine-tuning a Distilbert model, using self-annotated data, we find that 8.24{\%} of the sent messages contain signs of conspiracy narratives. This number is not static, however, as the share of conspiracy messages grew while the overall number of messages shows a downward trend since its peak at the end of 2020. We further find a mix of known conspiracy narratives make up the topics in our topic model. Our findings suggest that the Querdenken movement is getting smaller over time, but its remaining members focus even more on conspiracy narratives.",
}
@inproceedings{model-comparison,
author = {Zhao, Zhixue and Zhang, Ziqi and Hopfgartner, Frank},
title = {A Comparative Study of Using Pre-trained Language Models for Toxic Comment Classification},
year = {2021},
isbn = {9781450383134},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442442.3452313},
doi = {10.1145/3442442.3452313},
abstract = {As user-generated contents thrive, so does the spread of toxic comment. Therefore, detecting toxic comment becomes an active research area, and it is often handled as a text classification task. As recent popular methods for text classification tasks, pre-trained language model-based methods are at the forefront of natural language processing, achieving state-of-the-art performance on various NLP tasks. However, there is a paucity in studies using such methods on toxic comment classification. In this work, we study how to best make use of pre-trained language model-based methods for toxic comment classification and the performances of different pre-trained language models on these tasks. Our results show that, Out of the three most popular language models, i.e. BERT, RoBERTa, and XLM, BERT and RoBERTa generally outperform XLM on toxic comment classification. We also prove that using a basic linear downstream structure outperforms complex ones such as CNN and BiLSTM. What is more, we find that further fine-tuning a pre-trained language model with light hyper-parameter settings brings improvements to the downstream toxic comment classification task, especially when the task has a relatively small dataset.},
booktitle = {Companion Proceedings of the Web Conference 2021},
pages = {500–507},
numpages = {8},
keywords = {toxic comment, pre-training, neural networks, language model, hate speech, fine-tuning, XLM, RoBERTa, BERT},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}
@misc{tran2021ensemble,
  doi = {10.48415/2021/FHW5-X128},
  
  url = {https://resolver.obvsg.at/urn:nbn:at:at-ubk:3-798},
  
  author = {Risch, Julian and Stoll, Anke and Wilms, Lena and Wiegand, Michael},
  
  language = {en},
  
  title = {Proceedings of the GermEval 2021 Workshop on the Identification of Toxic, Engaging, and Fact-Claiming Comments},
  
  publisher = {Universität Klagenfurt},
  
  year = {2021}
}
